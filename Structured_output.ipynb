{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedmahmoodiagents/BigData/blob/main/Structured_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_core langchain_community langchain_openai --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ydMgdv50SoM",
        "outputId": "2d9a6ddf-d6ae-4b8e-d42a-da90e352c680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HQsrHBZ0qM_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai --q"
      ],
      "metadata": {
        "id": "VPi6zCaYqM2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "# from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ChatMessage, FunctionMessage"
      ],
      "metadata": {
        "id": "In6hHS8i1EBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass"
      ],
      "metadata": {
        "id": "FYynYtsj1J1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = getpass.getpass()\n",
        "os.environ['OPENAI_API_KEY'] = \"*********************************************\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58J3vDEw1LT_",
        "outputId": "79c0a672-fb1d-449b-ed6d-3ae5d4cc211c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat model (multi-turn, message-based)\n",
        "chat_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "1sJ67V2l2ru0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm.invoke(\"what is teh capital of france\")"
      ],
      "metadata": {
        "id": "V64o7inccZNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using HumanMessage"
      ],
      "metadata": {
        "id": "fHA88qBenm2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_llm.invoke([\n",
        "    HumanMessage(content=\"Explain transformers in 3 bullet points.\")\n",
        "])\n",
        "\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeez_I111Bsy",
        "outputId": "b3e48c3b-4908-45b5-9072-367cad0bc79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Architecture**: Transformers are a type of neural network architecture that relies on self-attention mechanisms to process input data, allowing them to weigh the importance of different parts of the input sequence when making predictions, rather than relying on sequential processing like RNNs.\n",
            "\n",
            "- **Scalability**: They are highly parallelizable, enabling efficient training on large datasets and making them suitable for tasks involving long-range dependencies, such as natural language processing, image recognition, and more.\n",
            "\n",
            "- **Pre-training and Fine-tuning**: Transformers often utilize a two-step training process: pre-training on a large corpus of data to learn general representations, followed by fine-tuning on specific tasks, which has led to significant advancements in performance across various applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0R7TVVq7C6Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pydantic"
      ],
      "metadata": {
        "id": "bHYswG9OwlCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class xyz:\n",
        "    x = 10\n",
        "    y = 20"
      ],
      "metadata": {
        "id": "kuXqnjahakyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class abc:\n",
        "    x = 15"
      ],
      "metadata": {
        "id": "yvUogI9targs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ob1 = abc()\n",
        "ob2 = abc()"
      ],
      "metadata": {
        "id": "76uwwGSXaz7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ob1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlWyFrg_a3jz",
        "outputId": "d464dc49-2b81-410d-acfe-2e9c92da8804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ob1.x = 17"
      ],
      "metadata": {
        "id": "5GY2cAqXbBjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ob1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDMHkxU-bQYM",
        "outputId": "4b6bada5-cc9f-4632-96f4-83cadd25c2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY61BygYbW5f",
        "outputId": "e351dd4d-9357-4d5c-d9b7-dba7befecba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class animal:\n",
        "    x = 15\n",
        "    y = 20"
      ],
      "metadata": {
        "id": "Ysk6_APqbxMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dog(animal):\n",
        "    x = 30"
      ],
      "metadata": {
        "id": "-SFnHdGgbxAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dog.y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey6gRKx1bwz-",
        "outputId": "c5b27361-db87-4a47-c594-1a088e2b6fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pydantic"
      ],
      "metadata": {
        "id": "XgtpI42MPctG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel"
      ],
      "metadata": {
        "id": "8aQgFdX6DFMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class User(BaseModel):\n",
        "    id: int\n",
        "    name: str\n",
        "    is_active: bool = True\n"
      ],
      "metadata": {
        "id": "veFKrTI2C9ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user = User(id=1, name=\"Alice\")"
      ],
      "metadata": {
        "id": "IxHgSqQlC__E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW36qeC6R1N1",
        "outputId": "aa1fc499-8bfe-4c64-fb73-ad36f20346c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "User(id=1, name='Alice', is_active=True)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(user.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Copjq3ApDCP7",
        "outputId": "621d9138-b516-43e4-a765-ac1568de51ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user.id + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7LCktzGDQEe",
        "outputId": "2ee1f003-0e8e-41c9-f77c-48e848d2a050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "# from langchain_core.output_parsers import JsonOutputParser"
      ],
      "metadata": {
        "id": "FBX9W5tF0Re5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "dG6AsHvMjZcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chat_llm.invoke(\"what is language spoken in france\")"
      ],
      "metadata": {
        "id": "O9FnxzafPplQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "sEbKRbSl6lQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Person(BaseModel):\n",
        "    name: str\n",
        "    age: str\n",
        "    # name: str = Field(description=\"The person's name\")\n",
        "    # age: int = Field(description=\"The person's age\")"
      ],
      "metadata": {
        "id": "YPYct3XZ6op8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm = chat_llm.with_structured_output(Person)"
      ],
      "metadata": {
        "id": "fU7L-8w66x06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the structured LLM\n",
        "result = structured_llm.invoke(\n",
        "    input=[\n",
        "        HumanMessage(content=\"Extract name and age from: John is 30.\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "fw_RyjH_3DQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzScrIEtnmCA",
        "outputId": "37d8994a-29b0-443c-b8af-9ccd8f9cd337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='John' age=30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The result will be a Pydantic object, you can convert it to JSON if needed\n",
        "print(result.model_dump_json(indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpjjSu5v615M",
        "outputId": "7359495b-840b-4674-dd70-470efd33d4a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"John\",\n",
            "  \"age\": 30\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One more example"
      ],
      "metadata": {
        "id": "cJKthCvWwzSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
      ],
      "metadata": {
        "id": "lCrdGwnSw7Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define schema\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"name\", description=\"User's full name\"),\n",
        "    ResponseSchema(name=\"age\", description=\"User's age\"),\n",
        "    ResponseSchema(name=\"email\", description=\"User's email\"),\n",
        "]"
      ],
      "metadata": {
        "id": "O7cYGKNsw9WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ],
      "metadata": {
        "id": "-03Zutdlw_yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a user profile.\n",
        "{parser.get_format_instructions()}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gk1aw5c_xCGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = chat_llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "ty7MhOd3m9f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0skF5WcxLj7",
        "outputId": "c830278a-739d-43e3-dd74-1063c1e586e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='```json\\n{\\n\\t\"name\": \"John Doe\",\\n\\t\"age\": \"30\",\\n\\t\"email\": \"johndoe@example.com\"\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 80, 'total_tokens': 112, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CdA09jIW6IOrFEuwVHJtIgNsgOUFB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--de8b1901-01f0-4ad4-b894-20b3ef7e779e-0', usage_metadata={'input_tokens': 80, 'output_tokens': 32, 'total_tokens': 112, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.parse(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu698_h8xHqy",
        "outputId": "bc02fb55-da5d-4cf2-c7fd-342b516e1736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'John Doe', 'age': '30', 'email': 'johndoe@example.com'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "GyeUbCtWxJU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define schema\n",
        "class UserProfile(BaseModel):\n",
        "    name: str = Field(..., description=\"User's full name\")\n",
        "    age: int = Field(..., description=\"User's age in years\")\n",
        "    email: str = Field(..., description=\"User's email address\")"
      ],
      "metadata": {
        "id": "6kt_9VcT0C-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create parser\n",
        "parser = PydanticOutputParser(pydantic_object=UserProfile)"
      ],
      "metadata": {
        "id": "IwSIkTOR0Fg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build prompt with format instructions\n",
        "prompt = f\"\"\"\n",
        "Generate a user profile in JSON format.\n",
        "{parser.get_format_instructions()}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Ehj1EARH0JXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "0P28gqTg0URo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZtTTPD_0X3a",
        "outputId": "0c52dc43-ec0f-4d01-97f6-eb5916a69b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='```json\\n{\\n  \"name\": \"John Doe\",\\n  \"age\": 30,\\n  \"email\": \"johndoe@example.com\"\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 225, 'total_tokens': 258, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CdADhJUSfLTGbWjWebB1rrL6ksgc5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--cfd57c6a-3277-46c3-98e2-51ef45b2d7ab-0', usage_metadata={'input_tokens': 225, 'output_tokens': 33, 'total_tokens': 258, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.parse(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79A5Z66V0cMy",
        "outputId": "22597c90-1a89-4180-815c-8bc2375b9c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UserProfile(name='John Doe', age=30, email='johndoe@example.com')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response Models"
      ],
      "metadata": {
        "id": "fcc5B_XIoNyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# response_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "j-Sk6ZRhm2yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function schema\n",
        "functions = [\n",
        "    {\n",
        "        \"name\": \"create_user_profile\",\n",
        "        \"description\": \"Generate a user profile\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\"},\n",
        "                \"age\": {\"type\": \"integer\"},\n",
        "                \"email\": {\"type\": \"string\"},\n",
        "            },\n",
        "            \"required\": [\"name\", \"age\", \"email\"],\n",
        "        },\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "a9OU_9omwPuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_llm.invoke(\"Generate a sample user profile\", functions=functions)\n"
      ],
      "metadata": {
        "id": "i5Z1eXCTnvqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps-BbPgCwVjM",
        "outputId": "59457c58-3f1a-4afd-fd6a-97d21ba5607c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"name\":\"John Doe\",\"age\":30,\"email\":\"johndoe@example.com\"}', 'name': 'create_user_profile'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 56, 'total_tokens': 85, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CdA2IMct0BYBBoxp1SaSKZkQlw5kg', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--702a810d-9315-4d64-b78d-0be73fc0cacf-0', usage_metadata={'input_tokens': 56, 'output_tokens': 29, 'total_tokens': 85, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.additional_kwargs[\"function_call\"][\"arguments\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4sgFC2VqwWhI",
        "outputId": "8ee0b8b2-607e-419f-c240-5064e932af30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"name\":\"John Doe\",\"age\":30,\"email\":\"johndoe@example.com\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GuardRails"
      ],
      "metadata": {
        "id": "Fzy3L_K-k9ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install guardrails-ai --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnX4ZFull9rt",
        "outputId": "df73f703-c9c3-4f6c-e261-4bb99d9d526a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m235.5/235.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/98.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.2/110.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_openai import ChatOpenAI\n",
        "from guardrails import Guard"
      ],
      "metadata": {
        "id": "zg8IjxdclBVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No explicit import needed for built-in validators like 'valid_email' when used in RAIL spec."
      ],
      "metadata": {
        "id": "wDCKrhFJtmXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rail_spec = \"\"\"\n",
        "<rail version=\"0.1\">\n",
        "  <output>\n",
        "    <object name=\"UserProfile\">\n",
        "      <string name=\"name\" description=\"User's full name\"/>\n",
        "      <integer name=\"age\" description=\"User's age\"/>\n",
        "      <string name=\"email\" description=\"User's email\"/>\n",
        "    </object>\n",
        "  </output>\n",
        "</rail>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KiaeSMGplGPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guard = Guard.from_rail_string(rail_spec)"
      ],
      "metadata": {
        "id": "h1okYH6llJH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chat_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "cb2Ifzk_lTJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Generate a sample user profile in JSON format.\""
      ],
      "metadata": {
        "id": "0ACCMYfglWI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_response = chat_llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "154Fcc6QlbYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOkdsNPyup52",
        "outputId": "502e7338-43f1-4492-98b3-4436f4714c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Here\\'s a sample user profile in JSON format:\\n\\n```json\\n{\\n  \"userId\": \"12345\",\\n  \"username\": \"johndoe\",\\n  \"email\": \"johndoe@example.com\",\\n  \"firstName\": \"John\",\\n  \"lastName\": \"Doe\",\\n  \"dateOfBirth\": \"1990-05-15\",\\n  \"gender\": \"male\",\\n  \"profilePicture\": \"https://example.com/images/johndoe.jpg\",\\n  \"bio\": \"Tech enthusiast and avid traveler. Love to explore new cultures and cuisines.\",\\n  \"location\": {\\n    \"city\": \"San Francisco\",\\n    \"state\": \"CA\",\\n    \"country\": \"USA\"\\n  },\\n  \"interests\": [\\n    \"Technology\",\\n    \"Traveling\",\\n    \"Photography\",\\n    \"Cooking\"\\n  ],\\n  \"socialMedia\": {\\n    \"twitter\": \"@johndoe\",\\n    \"linkedin\": \"https://linkedin.com/in/johndoe\",\\n    \"instagram\": \"https://instagram.com/johndoe\"\\n  },\\n  \"createdAt\": \"2021-01-01T12:00:00Z\",\\n  \"lastLogin\": \"2023-10-01T08:30:00Z\",\\n  \"isActive\": true\\n}\\n```\\n\\nThis JSON structure includes various attributes that might be relevant for a user profile, such as personal information, interests, and social media links. You can modify it as needed to fit your specific requirements.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 307, 'prompt_tokens': 16, 'total_tokens': 323, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CdECGWaW2ng7zcmkk8jxMNByCc3Fw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9e6712b3-fb57-4d2f-bda7-0389ac7d1149-0', usage_metadata={'input_tokens': 16, 'output_tokens': 307, 'total_tokens': 323, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "respo = raw_response.content"
      ],
      "metadata": {
        "id": "ird09UiFlekm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "mtgd1rMcutuG",
        "outputId": "7451e416-d1bf-4543-d378-f4c85a380580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here\\'s a sample user profile in JSON format:\\n\\n```json\\n{\\n  \"userId\": \"12345\",\\n  \"username\": \"johndoe\",\\n  \"email\": \"johndoe@example.com\",\\n  \"firstName\": \"John\",\\n  \"lastName\": \"Doe\",\\n  \"dateOfBirth\": \"1990-05-15\",\\n  \"gender\": \"male\",\\n  \"profilePicture\": \"https://example.com/images/johndoe.jpg\",\\n  \"bio\": \"Tech enthusiast and avid traveler. Love to explore new cultures and cuisines.\",\\n  \"location\": {\\n    \"city\": \"San Francisco\",\\n    \"state\": \"CA\",\\n    \"country\": \"USA\"\\n  },\\n  \"interests\": [\\n    \"Technology\",\\n    \"Traveling\",\\n    \"Photography\",\\n    \"Cooking\"\\n  ],\\n  \"socialMedia\": {\\n    \"twitter\": \"@johndoe\",\\n    \"linkedin\": \"https://linkedin.com/in/johndoe\",\\n    \"instagram\": \"https://instagram.com/johndoe\"\\n  },\\n  \"createdAt\": \"2021-01-01T12:00:00Z\",\\n  \"lastLogin\": \"2023-10-01T08:30:00Z\",\\n  \"isActive\": true\\n}\\n```\\n\\nThis JSON structure includes various attributes that might be relevant for a user profile, such as personal information, interests, and social media links. You can modify it as needed to fit your specific requirements.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid = guard.parse(respo)"
      ],
      "metadata": {
        "id": "d_ZiJpZuux98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5Ki-BQLvMrw",
        "outputId": "9e72e128-3089-4190-80da-ef69f3c33192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ValidationOutcome(call_id='133102026967152', raw_llm_output='Here\\'s a sample user profile in JSON format:\\n\\n```json\\n{\\n  \"userId\": \"12345\",\\n  \"username\": \"johndoe\",\\n  \"email\": \"johndoe@example.com\",\\n  \"firstName\": \"John\",\\n  \"lastName\": \"Doe\",\\n  \"dateOfBirth\": \"1990-05-15\",\\n  \"gender\": \"male\",\\n  \"profilePicture\": \"https://example.com/images/johndoe.jpg\",\\n  \"bio\": \"Tech enthusiast and avid traveler. Love to explore new cultures and cuisines.\",\\n  \"location\": {\\n    \"city\": \"San Francisco\",\\n    \"state\": \"CA\",\\n    \"country\": \"USA\"\\n  },\\n  \"interests\": [\\n    \"Technology\",\\n    \"Traveling\",\\n    \"Photography\",\\n    \"Cooking\"\\n  ],\\n  \"socialMedia\": {\\n    \"twitter\": \"@johndoe\",\\n    \"linkedin\": \"https://linkedin.com/in/johndoe\",\\n    \"instagram\": \"https://instagram.com/johndoe\"\\n  },\\n  \"createdAt\": \"2021-01-01T12:00:00Z\",\\n  \"lastLogin\": \"2023-10-01T08:30:00Z\",\\n  \"isActive\": true\\n}\\n```\\n\\nThis JSON structure includes various attributes that might be relevant for a user profile, such as personal information, interests, and social media links. You can modify it as needed to fit your specific requirements.', validation_summaries=[], validated_output=None, reask=SkeletonReAsk(incorrect_value={}, fail_results=[FailResult(outcome='fail', error_message='JSON does not match schema:\\n{\\n  \"$\": [\\n    \"\\'UserProfile\\' is a required property\"\\n  ]\\n}', fix_value=None, error_spans=None, metadata=None, validated_chunk=None)], additional_properties={}), validation_passed=False, error=None)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid.model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuO5pw3ClvcI",
        "outputId": "4224584b-099a-4bf4-e66f-603fc1776386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'call_id': '133102026967152',\n",
              " 'raw_llm_output': 'Here\\'s a sample user profile in JSON format:\\n\\n```json\\n{\\n  \"userId\": \"12345\",\\n  \"username\": \"johndoe\",\\n  \"email\": \"johndoe@example.com\",\\n  \"firstName\": \"John\",\\n  \"lastName\": \"Doe\",\\n  \"dateOfBirth\": \"1990-05-15\",\\n  \"gender\": \"male\",\\n  \"profilePicture\": \"https://example.com/images/johndoe.jpg\",\\n  \"bio\": \"Tech enthusiast and avid traveler. Love to explore new cultures and cuisines.\",\\n  \"location\": {\\n    \"city\": \"San Francisco\",\\n    \"state\": \"CA\",\\n    \"country\": \"USA\"\\n  },\\n  \"interests\": [\\n    \"Technology\",\\n    \"Traveling\",\\n    \"Photography\",\\n    \"Cooking\"\\n  ],\\n  \"socialMedia\": {\\n    \"twitter\": \"@johndoe\",\\n    \"linkedin\": \"https://linkedin.com/in/johndoe\",\\n    \"instagram\": \"https://instagram.com/johndoe\"\\n  },\\n  \"createdAt\": \"2021-01-01T12:00:00Z\",\\n  \"lastLogin\": \"2023-10-01T08:30:00Z\",\\n  \"isActive\": true\\n}\\n```\\n\\nThis JSON structure includes various attributes that might be relevant for a user profile, such as personal information, interests, and social media links. You can modify it as needed to fit your specific requirements.',\n",
              " 'validation_summaries': [],\n",
              " 'validated_output': None,\n",
              " 'reask': {'incorrect_value': {},\n",
              "  'fail_results': [{'outcome': 'fail',\n",
              "    'error_message': 'JSON does not match schema:\\n{\\n  \"$\": [\\n    \"\\'UserProfile\\' is a required property\"\\n  ]\\n}',\n",
              "    'fix_value': None,\n",
              "    'error_spans': None,\n",
              "    'metadata': None,\n",
              "    'validated_chunk': None}],\n",
              "  'additional_properties': {}},\n",
              " 'validation_passed': False,\n",
              " 'error': None}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}